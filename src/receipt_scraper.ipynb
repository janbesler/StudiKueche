{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import pytesseract\n",
    "from deskew import determine_skew\n",
    "import imutils\n",
    "import re\n",
    "\n",
    "import pytesseract\n",
    "import shutil\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = '/home/jan/miniconda3/bin/tesseract'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# picture preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed receipt saved to ../data/processed_receipts/test_processed.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance\n",
    "import imutils\n",
    "import os\n",
    "import math\n",
    "\n",
    "def find_receipt_in_image(image_path):\n",
    "    \"\"\"\n",
    "    Finds and extracts only the receipt portion using color thresholding\n",
    "    to better handle white receipts on darker backgrounds.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        \n",
    "    Returns:\n",
    "        The extracted receipt image as a numpy array\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image at {image_path}\")\n",
    "        \n",
    "    original = image.copy()\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply threshold to isolate white/light regions\n",
    "    # Use Otsu's method to automatically determine optimal threshold\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Clean up the threshold with morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort contours by area (largest first)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    # If no contours found, return original image\n",
    "    if not contours:\n",
    "        return original\n",
    "    \n",
    "    # Take the largest contour as the receipt\n",
    "    receipt_contour = contours[0]\n",
    "    \n",
    "    # Create a mask for the receipt\n",
    "    mask = np.zeros(gray.shape, dtype=np.uint8)\n",
    "    cv2.drawContours(mask, [receipt_contour], -1, 255, -1)\n",
    "    \n",
    "    # Apply the mask to extract just the receipt\n",
    "    receipt_only = cv2.bitwise_and(original, original, mask=mask)\n",
    "    \n",
    "    # Get a tight bounding rectangle around the receipt\n",
    "    x, y, w, h = cv2.boundingRect(receipt_contour)\n",
    "    cropped = receipt_only[y:y+h, x:x+w]\n",
    "    \n",
    "    # Return original if crop is too small\n",
    "    if cropped.size == 0 or w < image.shape[1] * 0.2 or h < image.shape[0] * 0.2:\n",
    "        return original\n",
    "        \n",
    "    return cropped\n",
    "\n",
    "def determine_skew(image):\n",
    "    \"\"\"\n",
    "    Determine the skew angle of text in an image.\n",
    "    \n",
    "    Args:\n",
    "        image: Grayscale input image\n",
    "        \n",
    "    Returns:\n",
    "        The skew angle in degrees\n",
    "    \"\"\"\n",
    "    # Apply threshold\n",
    "    _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Enhance horizontal lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 1))\n",
    "    morph = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    angles = []\n",
    "    weights = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Skip very small contours\n",
    "        if cv2.contourArea(contour) < 100:\n",
    "            continue\n",
    "            \n",
    "        # Get minimum area rectangle\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        angle = rect[2]\n",
    "        \n",
    "        # Normalize angle\n",
    "        if angle < -45:\n",
    "            angle = 90 + angle\n",
    "        elif angle > 45:\n",
    "            angle = angle - 90\n",
    "            \n",
    "        angles.append(angle)\n",
    "        weights.append(cv2.arcLength(contour, True))\n",
    "    \n",
    "    # Return weighted average angle if we have contours\n",
    "    if angles:\n",
    "        return np.average(angles, weights=weights)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "def deskew_image(image):\n",
    "    \"\"\"\n",
    "    Corrects skew using a gentler approach that preserves detail.\n",
    "    \n",
    "    Args:\n",
    "        image: The input image as numpy array\n",
    "        \n",
    "    Returns:\n",
    "        The deskewed image\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Determine skew angle\n",
    "    angle = determine_skew(gray)\n",
    "    \n",
    "    # Only correct if angle is significant (>1 degree)\n",
    "    if abs(angle) > 1:\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        \n",
    "        # Rotate with cubic interpolation and border replication\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h), \n",
    "                                flags=cv2.INTER_CUBIC, \n",
    "                                borderMode=cv2.BORDER_REPLICATE)\n",
    "        return rotated\n",
    "    \n",
    "    return image\n",
    "\n",
    "def correct_orientation(image):\n",
    "    \"\"\"\n",
    "    Makes sure text in the receipt is right-side up by comparing OCR confidence\n",
    "    in different orientations.\n",
    "    \n",
    "    Args:\n",
    "        image: The input image\n",
    "        \n",
    "    Returns:\n",
    "        The correctly oriented image\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if not already\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "    \n",
    "    # Only test upright vs upside-down (0째 and 180째)\n",
    "    orientations = [\n",
    "        gray,                              # Original (0째)\n",
    "        cv2.rotate(gray, cv2.ROTATE_180)   # Upside down (180째)\n",
    "    ]\n",
    "    \n",
    "    best_orientation = 0\n",
    "    best_confidence = -1\n",
    "    \n",
    "    for i, img in enumerate(orientations):\n",
    "        # Enhance the image for OCR\n",
    "        _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Use Tesseract to get OCR data with confidence values\n",
    "        try:\n",
    "            ocr_data = pytesseract.image_to_data(binary, config='--psm 11', output_type=pytesseract.Output.DICT)\n",
    "            \n",
    "            # Calculate average confidence (ignoring zero confidences)\n",
    "            confidences = [conf for conf in ocr_data['conf'] if conf > 0]\n",
    "            avg_confidence = sum(confidences) / len(confidences) if confidences else 0\n",
    "            \n",
    "            # Count words with reasonable confidence\n",
    "            valid_words = sum(1 for conf in ocr_data['conf'] if conf > 30)\n",
    "            \n",
    "            # Combined score: average confidence * number of valid words\n",
    "            score = avg_confidence * valid_words\n",
    "            \n",
    "            if score > best_confidence:\n",
    "                best_confidence = score\n",
    "                best_orientation = i\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"OCR error during orientation detection: {e}\")\n",
    "            # If OCR fails, keep the original orientation\n",
    "            pass\n",
    "    \n",
    "    # If OCR-based detection failed or gave low confidence overall, \n",
    "    # just keep the original orientation\n",
    "    if best_confidence < 10:\n",
    "        return image\n",
    "    \n",
    "    # Apply the selected orientation to the original image\n",
    "    if best_orientation == 0:\n",
    "        return image\n",
    "    else:\n",
    "        return cv2.rotate(image, cv2.ROTATE_180)\n",
    "\n",
    "def enhance_for_ocr(image, binarize=False):\n",
    "    \"\"\"\n",
    "    Enhances an image for OCR with emphasis on preserving detail and readability.\n",
    "    \n",
    "    Args:\n",
    "        image: The input image (numpy array)\n",
    "        binarize: Whether to return a binary or grayscale image (default: False)\n",
    "        \n",
    "    Returns:\n",
    "        Enhanced image as numpy array\n",
    "    \"\"\"\n",
    "    # Convert to PIL for enhancement operations\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 3:\n",
    "            pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            pil_img = Image.fromarray(image)\n",
    "    else:\n",
    "        pil_img = image\n",
    "    \n",
    "    # Moderate contrast enhancement\n",
    "    enhancer = ImageEnhance.Contrast(pil_img)\n",
    "    enhanced = enhancer.enhance(1.3)  # Reduced from 1.5\n",
    "    \n",
    "    # Convert back to numpy\n",
    "    np_img = np.array(enhanced)\n",
    "    \n",
    "    # Convert to grayscale if needed\n",
    "    if len(np_img.shape) == 3:\n",
    "        gray = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = np_img\n",
    "    \n",
    "    # Improve contrast using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_gray = clahe.apply(gray)\n",
    "    \n",
    "    # Apply gentle Gaussian blur to reduce noise without losing detail\n",
    "    denoised = cv2.GaussianBlur(enhanced_gray, (3, 3), 0)\n",
    "    \n",
    "    # Apply unsharp masking for crisp edges\n",
    "    gaussian = cv2.GaussianBlur(denoised, (0, 0), 3.0)\n",
    "    unsharp_mask = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)\n",
    "    \n",
    "    # If binary output is requested, apply Otsu's thresholding\n",
    "    if binarize:\n",
    "        _, binary = cv2.threshold(unsharp_mask, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return binary\n",
    "    \n",
    "    return unsharp_mask\n",
    "\n",
    "def process_receipt_for_gemini(image_path, output_path=None, binarize=False):\n",
    "    \"\"\"\n",
    "    Process a receipt image for optimal OCR with improved enhancement.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        output_path: Path to save the processed image\n",
    "        binarize: Whether to binarize the final image (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        The processed image ready for API submission\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Extract receipt from image\n",
    "        receipt_only = find_receipt_in_image(image_path)\n",
    "        \n",
    "        # Step 2: Correct skew with improved angle detection\n",
    "        deskewed = deskew_image(receipt_only)\n",
    "        \n",
    "        # Step 3: Fix orientation with improved confidence-based detection\n",
    "        oriented = correct_orientation(deskewed)\n",
    "        \n",
    "        # Step 4: Enhance for OCR with improved detail preservation\n",
    "        enhanced = enhance_for_ocr(oriented, binarize=binarize)\n",
    "        \n",
    "        # Save result if output path provided\n",
    "        if output_path:\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            cv2.imwrite(output_path, enhanced, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "            print(f\"Processed receipt saved to {output_path}\")\n",
    "        \n",
    "        return enhanced\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing receipt: {e}\")\n",
    "        return cv2.imread(image_path) if os.path.exists(image_path) else None\n",
    "\n",
    "def main():\n",
    "    input_path = \"../data/receipts/test.png\"\n",
    "    output_path = \"../data/processed_receipts/test_processed.png\"\n",
    "    \n",
    "    processed_img = process_receipt_for_gemini(input_path, output_path)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
